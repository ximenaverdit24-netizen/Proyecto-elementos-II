# Proyecto: Plataforma controlada por gestos de la mano

---

## 1) Resumen

- **Equipo / Autor(es):** Ximena Guadalupe Verdi Toledo  
- **Curso / Asignatura:** Elementos Programables II  
- **Fecha:** 07/12/2025  

**Descripci√≥n breve:**  
Este proyecto implementa una plataforma tipo **Stewart** de 3 grados de libertad controlada mediante **gestos de la mano**.  
El sistema utiliza **visi√≥n por computadora con MediaPipe** para detectar los landmarks de la mano (mu√±eca, dedo medio y pulgar) y, a partir de ellos, calcular los √°ngulos de **pitch** (inclinaci√≥n arriba/abajo) y **roll** (inclinaci√≥n izquierda/derecha).

Los valores calculados se filtran con un **filtro exponencial** para suavizar el movimiento y, posteriormente, se env√≠an por **Bluetooth Classic** a un **ESP32**, el cual controla **tres servomotores MG90S** en configuraci√≥n triangular mediante **PWM a 50 Hz**.  
El firmware del ESP32 recibe comandos del tipo `ANG:x,y,z`, aplica rampas de movimiento y posiciona cada servo para inclinar la plataforma de acuerdo con los gestos del usuario.

---

## 2) Objetivos

### üéØ Objetivo general
Desarrollar un sistema de control para una plataforma Stewart de 3 grados de libertad, utilizando **reconocimiento de gestos de la mano** con visi√≥n por computadora y **comunicaci√≥n inal√°mbrica Bluetooth** hacia un ESP32 que gobierna los servomotores.

### üéØ Objetivos espec√≠ficos

- **OP1.** Implementar la detecci√≥n de la mano en tiempo real con **MediaPipe**, obteniendo los landmarks de mu√±eca, dedo medio y pulgar.  
- **OP2.** Calcular los par√°metros de inclinaci√≥n (**pitch** y **roll**) a partir de las posiciones relativas de estos puntos y aplicar filtros para reducir ruido y temblor.  
- **OP3.** Establecer comunicaci√≥n Bluetooth entre el programa en **Python** y el **ESP32**, transmitiendo peri√≥dicamente los √°ngulos calculados.  
- **OP4.** Controlar 3 servomotores **MG90S** mediante se√±ales **PWM** generadas por el ESP32, de forma que la plataforma reproduzca de manera estable los gestos del usuario.

---

## 3) Alcance y exclusiones

### ‚úÖ Alcance
- Dise√±o e impresi√≥n 3D de la **estructura de la plataforma Stewart** (base, brazos y soportes).  
- Implementaci√≥n de un script en **Python** con OpenCV + MediaPipe para:  
  - Captura de video.  
  - Detecci√≥n de mano.  
  - C√°lculo de pitch y roll.  
  - Filtrado exponencial de las se√±ales.  
- Implementaci√≥n de firmware en **ESP32** para:
  - Recepci√≥n de comandos v√≠a Bluetooth (`ANG:x,y,z`).  
  - Conversi√≥n a **PWM de 12 bits, 50 Hz**.  
  - Movimiento suave de los servos mediante rampa y l√≠mites de seguridad.  

### üö´ Exclusiones / restricciones
- No se utiliza realimentaci√≥n de posici√≥n de los servos (no hay encoders).  
- No se implementa un controlador PID formal; el control se basa en mapeos directos de los gestos y filtrado EMA.  
- La detecci√≥n de la mano asume **buena iluminaci√≥n** y una sola mano en cuadro.  
- No se implementa seguimiento autom√°tico de pelota, solo control manual por gestos.

---

## 4) Resultados

Al ejecutar el sistema completo:

1. La c√°mara capta la imagen de la mano del usuario en tiempo real.  
2. **MediaPipe** detecta autom√°ticamente los landmarks de mu√±eca, dedo medio y pulgar.  
3. Con estas posiciones se calculan:
   - El **pitch**, a partir de la diferencia en profundidad (eje Z).  
   - El **roll**, a partir de la diferencia vertical entre mu√±eca y pulgar.  
4. Ambos valores se filtran con un **promedio exponencial** para reducir vibraciones.  
5. Los √°ngulos resultantes se codifican como `ANG:izq,arriba,der` y se env√≠an al ESP32 v√≠a **Bluetooth**.  
6. El **ESP32** interpreta los datos, aplica una rampa de movimiento y genera las se√±ales PWM necesarias para los 3 servos **MG90S**, inclinando la plataforma.

Se obtuvo una respuesta **suave, estable y en tiempo real**, lo que demuestra que se puede implementar control de plataformas rob√≥ticas de forma intuitiva utilizando visi√≥n por computadora y actuadores econ√≥micos.

---

### üìå 5.1 Script Python ‚Äì Control por gestos

```python
import cv2
import mediapipe as mp
import time
import bluetooth

# ================== CONEXI√ìN BLUETOOTH ==================

PORT = 1
ESP32_MAC = "14:33:5C:02:4D:2A"   # CAMBIA a la MAC de tu ESP32

sock = bluetooth.BluetoothSocket()
sock.settimeout(20)

print("Intentando conectar al ESP32...")
while True:
    try:
        sock.connect((ESP32_MAC, PORT))
        print("¬°Conectado al ESP32!")
        break
    except Exception as e:
        print("Error en conexi√≥n... reintentando:", e)
        time.sleep(1)

def send_bt(message: str):
    try:
        sock.send(message.encode())
        print("Enviado:", message.strip())
    except:
        print("Error enviando datos")


# ================== MEDIAPIPE ==================

mp_hands = mp.solutions.hands
hands = mp_hands.Hands(max_num_hands=1,
                       min_detection_confidence=0.6,
                       min_tracking_confidence=0.5)
mp_draw = mp.solutions.drawing_utils

cap = cv2.VideoCapture(0)

# ===== FILTROS =====
pitch_filtrado = 0
roll_filtrado = 0
alpha = 0.25

ultimo_envio = time.time()
intervalo_envio = 0.05

# ===== HOME =====
HOME_IZQ = 90
HOME_ARRIBA = 90
HOME_DER = 90

# ===== GANANCIAS =====
K_pitch = 30.0
K_roll  = 0.05
K_lat   = 85.0
K_mid_acompa = 20.0


while cap.isOpened():

    ret, img = cap.read()
    if not ret:
        break

    img = cv2.flip(img, 1)
    rgb = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)
    results = hands.process(rgb)
    h, w, _ = img.shape

    detectada = False

    if results.multi_hand_landmarks:
        for hand in results.multi_hand_landmarks:
            detectada = True
            mp_draw.draw_landmarks(img, hand, mp_hands.HAND_CONNECTIONS)

            muneca = hand.landmark[0]
            medio  = hand.landmark[12]
            pulgar = hand.landmark[4]

            wx, wy = int(muneca.x*w), int(muneca.y*h)
            mx, my = int(medio.x*w),  int(medio.y*h)
            px, py = int(pulgar.x*w), int(pulgar.y*h)

            cv2.circle(img, (wx,wy), 10, (255,0,0), -1)
            cv2.circle(img, (mx,my), 10, (0,255,0), -1)
            cv2.circle(img, (px,py), 10, (0,0,255), -1)

            pitch = (muneca.z - medio.z) * 1.8
            pitch = max(-1, min(1, pitch))

            dy = wy - py
            roll = dy * K_roll
            roll = max(-1, min(1, roll))

            pitch_filtrado = (1-alpha)*pitch_filtrado + alpha*pitch
            roll_filtrado  = (1-alpha)*roll_filtrado  + alpha*roll

            if abs(pitch_filtrado) < 0.05:
                pitch_filtrado = 0
            if abs(roll_filtrado) < 0.05:
                roll_filtrado = 0

            a_arriba = HOME_ARRIBA + K_pitch*pitch_filtrado + K_mid_acompa*abs(roll_filtrado)

            delta_lat = K_lat * roll_filtrado
            a_izq = HOME_IZQ - delta_lat
            a_der = HOME_DER + delta_lat

            a_izq += (K_pitch*0.25)*pitch_filtrado
            a_der += (K_pitch*0.25)*pitch_filtrado

            a_izq = int(max(0, min(180, a_izq)))
            a_arriba = int(max(0, min(180, a_arriba)))
            a_der = int(max(0, min(180, a_der)))

            if time.time() - ultimo_envio >= intervalo_envio:
                msg = f"ANG:{a_izq},{a_arriba},{a_der}\n"
                send_bt(msg)
                ultimo_envio = time.time()

    if not detectada:
        cv2.putText(img, "No se detecta mano", (10,30),
                    cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0,0,255), 2)

    cv2.imshow("STEWART CONTROL PULGAR", img)

    k = cv2.waitKey(1)
    if k == ord('q'):
        break
    if k == ord('z') or k == ord('c'):
        send_bt("ZERO\n")

sock.close()
cap.release()
cv2.destroyAllWindows()
print("Programa terminado")
```

## 6) Conclusi√≥n

El proyecto logr√≥ integrar de forma pr√°ctica varias √°reas vistas en la materia **Elementos Programables II**:

- Procesamiento de imagen en tiempo real con **OpenCV + MediaPipe**.  
- Comunicaci√≥n inal√°mbrica mediante **Bluetooth Classic** entre una PC y un microcontrolador.  
- Generaci√≥n y control de se√±ales **PWM** para servomotores con un **ESP32**.  
- Dise√±o y fabricaci√≥n de una estructura mec√°nica mediante **impresi√≥n 3D**.

La plataforma Stewart controlada por gestos de la mano muestra c√≥mo, con componentes accesibles y herramientas de software libres, es posible construir un sistema interactivo que combina visi√≥n por computadora y control de movimiento.  
Como trabajo futuro se podr√≠an integrar modos adicionales de control (por ejemplo, seguimiento autom√°tico de pelota, control PID completo o interfaz gr√°fica) y optimizar la estructura mec√°nica para mejorar la precisi√≥n y la velocidad de respuesta.
